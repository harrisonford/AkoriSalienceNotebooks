{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Akori Web Proyect Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* [Abstract](#abstract)\n",
    "* [Simple Heatmap](#simple_heatmap)\n",
    "* [Priority Map](#priority_map)\n",
    "* [Salience Map](#salience_map)\n",
    "* [Salience Performance](#salience_metrics)\n",
    "* [Spacial Bias](#spacial_bias)\n",
    "* [Structural Bias](#struct_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='abstract'></a>\n",
    "## Abstract\n",
    "When the cognitive mechanisms that affect attention in the human brain are studied, the eye-movement behaviour is a good source of information to research it's process given that the visual pathways in the brain have been amply studied. When characterizing which processes influence attentional behaviour, these can be represented through what is called a salience model, where three principal sub-processes are often represented: bottom-up influence contains elements which relate to pre-attentional stimulus, inherently present in the image. Top-down influence is the container of attentional influences that are considered high-level processing by the brain, recruiting many cortical areas and being task-dependant. Finally, spacial inhibitory influence is needed which rewards the exploring of new areas in the visual field. Bottom-up influence has been the most studied because of it's direct relation to visual cortical areas that process physical patterns, such as colour, intensity of light, orientation, etc. Leaving top-down influence and inhibitory patterns as a compliment to encapsulate behaviours which are not defined yet and explained as a bias. This approach doesn't allow a real-life understanding of many human tasks and is only effective for very basic ones; Given a certain task, how can we distinguish possible top-down channels which are more relevant when characterizing eye-movement and thus attention? Answering this question could achieve a better mathematical model. In this study a method is proposed to separate top-down influence channels specifically using a human free-viewing experiment in a web-page environment. First, given humans are highly trained by every-day life in web-exploring, we expected a high top-down bias in their behaviour (poor prediction with bottom-up models like Itti-Koch). Second, we expected to discern which top-down patterns are influencing the most in this task in particular. Finally, a mathematical exploratory method to apply this work to other tasks is established, which allows to further develop theory in how both bottom-up and top-down patterns interact and is processed in the human brain.(**TODO: acortar y agregar reporte de resultados de modelo de saliencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset used\n",
    "The Akori-web dataset is a collection of 80 subjects recorded at Pedro Maldonado's Neurosistemas Laboratory (neurosistemas.cl) from Universidad de Chile. Subjects' age ranged from (**TODO: completar info del dataset y postear imagen del protocolo experimental) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='simple_heatmap'></a>\n",
    "## Making a simple heatmap\n",
    "First, we explore what subjects eye movement looks like with a heatmap visualization. Given a certain image, we'll make heatmap for all subjects, to achieve this we need a function that loads a subject from the dataset as a fixation map and then apply a gaussian filtered version on top of the webpage. We saved these functions in our *scripts/* folder as they can be used many times in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scripts.intro_heatmap as intro\n",
    "\n",
    "\n",
    "# Show the heatmap inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 500  # image quality\n",
    "plt.rcParams['figure.figsize'] = [10, 5]  # image size\n",
    "\n",
    "page = 'Banco de Chile'  # page name\n",
    "number = 1  # page number\n",
    "sigma = 30  # guassian parameter\n",
    "ignored = 1  # ignore first n-fixations\n",
    "transparency = 0.7  # of heatmap overlay\n",
    "\n",
    "# Make a list of subjects\n",
    "dataset_dir = os.listdir('dataset/')  # strip .csv from names\n",
    "for index, subject in enumerate(dataset_dir):\n",
    "    dataset_dir[index] = subject[:-4]\n",
    "    \n",
    "# Make initial fixmap with first subject\n",
    "total_fixmap, webpage = intro.load_csv_fixmap(dataset_dir[0], page, number, ignored)\n",
    "dataset_dir.pop(0)\n",
    "# Add the rest of fixmaps to total\n",
    "for subject in dataset_dir:\n",
    "    fixmap = intro.load_csv_fixmap(subject, page, number, ignored)[0]\n",
    "    total_fixmap += fixmap\n",
    "\n",
    "# Now make heatmap\n",
    "total_heatmap = intro.make_heatmap(total_fixmap, sigma)\n",
    "\n",
    "# Visualize results\n",
    "plt.imshow(webpage)\n",
    "plt.imshow(total_heatmap, alpha=transparency)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='priority_heatmap'></a>\n",
    "## Making a priority heatmap\n",
    "\n",
    "A heatmap is good as a qualitative representation of what subjects look most, but we could also be interested in what subject looks first too. To make a simple representation of what areas in the image have more priority to users we'll make a heatmap but using fixation order in the fix-map in replacement of fixation duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.intro_heatmap as intro\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 500  # image quality\n",
    "plt.rcParams['figure.figsize'] = [10, 5]  # image size\n",
    "\n",
    "page = 'Banco de Chile'\n",
    "page_number = 1\n",
    "sigma = 30\n",
    "transparency = 0.7\n",
    "ignored_fixations = 1\n",
    "\n",
    "dataset_dir = os.listdir('dataset/')  # take .csv from names\n",
    "for index, subject in enumerate(dataset_dir):\n",
    "    dataset_dir[index] = subject[:-4]\n",
    "    \n",
    "# Make initial priority-map\n",
    "total_prioritymap, webpage = intro.load_csv_prioritymap(dataset_dir[0], page, page_number, ignored_fixations)\n",
    "dataset_dir.pop(0)\n",
    "# Add the rest of fixmaps to total\n",
    "for subject in dataset_dir:\n",
    "    prioritymap = intro.load_csv_prioritymap(subject, page, page_number, ignored_fixations)[0]\n",
    "    total_prioritymap += prioritymap\n",
    "\n",
    "# Now make heatmap\n",
    "total_heatmap = intro.make_heatmap(total_prioritymap, sigma)\n",
    "\n",
    "# Visualize results\n",
    "plt.imshow(webpage)\n",
    "plt.imshow(total_heatmap, alpha=transparency)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='salience_map'></a>\n",
    "## Computing Salience Map\n",
    "In this project we start by computing *TODO: Utilizar saliency map ac√°*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='spacial_bias'></a>\n",
    "## Exploring Spacial Bias in Behaviour\n",
    "From priority map computation we suspect subjects may have a spacial bias (top-left) when exploring a web-page, if this is true, the average priority map should be biased towards top-left independant of webpage, for this reason we compute a grand average heatmap of the whole database. (*TODO: In work*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='struct_bias'></a>\n",
    "## Exploring Structural Bias in Behaviour\n",
    "\n",
    "Subjects may show a bias towards certain objects types in the image (i.e: pictures over text), we want to explore this phenomena to be able to refine or specialize our salience map towards web-page environments. (TODO: *After spacial bias*)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
