{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Akori Web Proyect Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* [Abstract](#abstract)\n",
    "* [Simple Heatmap](#simple_heatmap)\n",
    "* [Priority Map](#priority_map)\n",
    "* [Salience Map](#salience_map)\n",
    "\t- [Pre-trained Performance](#pretrained)\n",
    "\t- [Trained Performance](#trained)\n",
    "* [Spacial Bias](#spacial_bias)\n",
    "* [Structural Bias](#struct_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='abstract'></a>\n",
    "## Abstract\n",
    "When the cognitive mechanisms that affect attention in the human brain are studied, the eye-movement behaviour is a good source of information to research it's process given that the visual pathways in the brain have been amply studied. When characterizing which processes influence attentional behaviour, these can be represented through what is called a salience model, where three principal sub-processes are often represented: bottom-up influence contains elements which relate to pre-attentional stimulus, inherently present in the image. Top-down influence is the container of attentional influences that are considered high-level processing by the brain, recruiting many cortical areas and being task-dependant. Finally, spacial inhibitory influence is needed which rewards the exploring of new areas in the visual field. Bottom-up influence has been the most studied because of it's direct relation to visual cortical areas that process physical patterns, such as colour, intensity of light, orientation, etc. Leaving top-down influence and inhibitory patterns as a compliment to encapsulate behaviours which are not defined yet and explained as a bias. This approach doesn't allow a real-life understanding of many human tasks and is only effective for very basic ones; Given a certain task, how can we distinguish possible top-down channels which are more relevant when characterizing eye-movement and thus attention? Answering this question could achieve a better mathematical model. In this study a method is proposed to separate top-down influence channels specifically using a human free-viewing experiment in a web-page environment. First, given humans are highly trained by every-day life in web-exploring, we expected a high top-down bias in their behaviour (poor prediction with bottom-up models like Itti-Koch). Second, we expected to discern which top-down patterns are influencing the most in this task in particular. Finally, a mathematical exploratory method to apply this work to other tasks is established, which allows to further develop theory in how both bottom-up and top-down patterns interact and is processed in the human brain.(**TODO: acortar y agregar reporte de resultados de modelo de saliencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset used\n",
    "The Akori-web dataset is a collection of 80 subjects recorded at Pedro Maldonado's Neurosistemas Laboratory (neurosistemas.cl) from Universidad de Chile. Subjects' age ranged from (**TODO: completar info del dataset y postear imagen del protocolo experimental) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='simple_heatmap'></a>\n",
    "## Making a simple heatmap\n",
    "First, we explore what subjects eye movement looks like with a heatmap visualization. Given a certain image, we'll make heatmap for all subjects, to achieve this we need a function that loads a subject from the dataset as a fixation map and then apply a gaussian filtered version on top of the webpage. We saved these functions in our *scripts/* folder as they can be used many times in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scripts.data_loader as loader\n",
    "\n",
    "\n",
    "# Show the heatmap inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 500  # image quality\n",
    "plt.rcParams['figure.figsize'] = [10, 5]  # image size\n",
    "\n",
    "page = 'Banco de Chile'  # page name\n",
    "number = 1  # page number\n",
    "sigma = 30  # guassian parameter\n",
    "ignored = 2  # ignore first n-fixations\n",
    "transparency = 0.7  # of heatmap overlay\n",
    "\n",
    "# Make a list of subjects\n",
    "dataset_dir = os.listdir('dataset/') \n",
    "    \n",
    "# Make initial fixmap with first subject\n",
    "total_fixmap, webpage = loader.csv_fixmap(dataset_dir, page, number, ignore=ignored, map='time', norm=True)\n",
    "\n",
    "# Now make heatmap\n",
    "total_heatmap = loader.make_heatmap(total_fixmap, sigma)\n",
    "\n",
    "# Visualize results\n",
    "plt.imshow(webpage)\n",
    "plt.imshow(total_heatmap, alpha=transparency)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='priority_heatmap'></a>\n",
    "## Making a priority heatmap\n",
    "\n",
    "A heatmap is good as a qualitative representation of what subjects look most, but we could also be interested in what subject looks first too. To make a simple representation of what areas in the image have more priority to users we'll make a heatmap but using fixation order in the fix-map in replacement of fixation duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scripts.data_loader as loader\n",
    "\n",
    "\n",
    "# Show the heatmap inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 500  # image quality\n",
    "plt.rcParams['figure.figsize'] = [10, 5]  # image size\n",
    "\n",
    "page = 'Banco de Chile'  # page name\n",
    "number = 1  # page number\n",
    "sigma = 30  # guassian parameter\n",
    "ignored = 2  # ignore first n-fixations\n",
    "transparency = 0.7  # of heatmap overlay\n",
    "\n",
    "# Make a list of subjects\n",
    "dataset_dir = os.listdir('dataset/') \n",
    "    \n",
    "# Make initial fixmap with first subject\n",
    "total_fixmap, webpage = loader.csv_fixmap(dataset_dir, page, number, ignore=ignored, map='priority', norm=True)\n",
    "\n",
    "# Now make heatmap\n",
    "total_heatmap = loader.make_heatmap(total_fixmap, sigma)\n",
    "\n",
    "# Visualize results\n",
    "plt.imshow(webpage)\n",
    "plt.imshow(total_heatmap, alpha=transparency)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='salience_map'></a>\n",
    "## Computing Salience Map\n",
    "The final achievement of this project is predicting user's ocular behaviour when exploring web-pages, to achieve the best possible result, we believe fusing the best performance algorithm's from the engineering field with the expertise in attentional mechanisms from neuroscience will achieve the best possible result. To prove this we start by using a pre-trained model with non-web database *TODO: agregar explicaci√≥n del benchmark del MIT*, followed by a trained method of the same algorithm and a final optimization to the algorithm to specialize it to web-page environments. For each model we use NSS and AUC-Judd to quantify performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pretrained'></a>\n",
    "### Pre-trained SAM-salience model vs All database\n",
    "\n",
    "For a trained model we already computed results in */predictions_sam/* folder just to save time and processing power (TODO: Migrate this process to my free Amazon Web Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Adidas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Banco BBVA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Banco de Chile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Banco Estado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Banco Santander\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Claro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Dafiti\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Entel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Falabella\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Groupon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Mercado Libre\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Movistar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page Ripley\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page VTR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2844139086121593\n"
     ]
    }
   ],
   "source": [
    "from scripts.salience_metrics import nss\n",
    "from PIL import Image\n",
    "import os\n",
    "import scripts.data_loader as loader\n",
    "import numpy as np\n",
    "\n",
    "scores = []\n",
    "\n",
    "ignored = 2  # ignore first n-fixations\n",
    "page_set = os.listdir('pages/')\n",
    "subject_set = os.listdir('dataset/')\n",
    "\n",
    "for a_page in page_set:  # we compute all five sub-pages\n",
    "    print(\"Processing page \" + a_page)\n",
    "    sub_page_set = os.listdir(\"pages/{page}/\".format(page=a_page))\n",
    "    for number in range(5):\n",
    "        # Make fixmap\n",
    "        total_fixmap, webpage = loader.csv_fixmap(subject_set, a_page, number+1, ignore=ignored, map='time', norm=True)\n",
    "        # Load pre-trained salience\n",
    "        image_id = \"{page} {num}_salience.jpg\".format(page=a_page, num=number+1)\n",
    "        salmap = np.array(Image.open(\"predictions_sam/{page} {num}_salience.jpg\".format(page=a_page, num=number+1)))\n",
    "        salmap_normalized = salmap/salmap.max()  # normalize saliency map\n",
    "        # Compute score\n",
    "        scores.append(nss(salmap_normalized, total_fixmap))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='spacial_bias'></a>\n",
    "## Exploring Spacial Bias in Behaviour\n",
    "From priority map computation we suspect subjects may have a spacial bias (top-left) when exploring a web-page, if this is true, the average priority map should be biased towards top-left independant of webpage, for this reason we compute a grand average heatmap of the whole database. (*TODO: In work*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='struct_bias'></a>\n",
    "## Exploring Structural Bias in Behaviour\n",
    "\n",
    "Subjects may show a bias towards certain objects types in the image (i.e: pictures over text), we want to explore this phenomena to be able to refine or specialize our salience map towards web-page environments. (TODO: *After spacial bias*)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
